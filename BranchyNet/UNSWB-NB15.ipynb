{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e2c1364",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_and_prepare_nb15\n",
    "from neural_network import *\n",
    "from dense_branchynet import *\n",
    "import time\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "numerical_cols = [\n",
    "    \"NUM_PKTS_128_TO_256_BYTES\",\n",
    "    \"RETRANSMITTED_OUT_PKTS\",\n",
    "    \"SRC_TO_DST_IAT_STDDEV\",\n",
    "    \"SRC_TO_DST_SECOND_BYTES\",\n",
    "    \"IN_PKTS\",\n",
    "    \"LONGEST_FLOW_PKT\",\n",
    "    \"NUM_PKTS_256_TO_512_BYTES\",\n",
    "    \"DST_TO_SRC_IAT_AVG\",\n",
    "    \"OUT_BYTES\",\n",
    "    \"NUM_PKTS_UP_TO_128_BYTES\",\n",
    "    \"DURATION_OUT\",\n",
    "    \"NUM_PKTS_512_TO_1024_BYTES\",\n",
    "    \"SRC_TO_DST_IAT_AVG\",\n",
    "    \"DURATION_IN\",\n",
    "    \"SHORTEST_FLOW_PKT\",\n",
    "    \"RETRANSMITTED_IN_PKTS\",\n",
    "    \"FLOW_DURATION_MILLISECONDS\",\n",
    "    \"IN_BYTES\",\n",
    "    \"MIN_IP_PKT_LEN\",\n",
    "    \"TCP_WIN_MAX_OUT\",\n",
    "    \"SRC_TO_DST_IAT_MIN\",\n",
    "    \"RETRANSMITTED_OUT_BYTES\",\n",
    "    \"DST_TO_SRC_IAT_MAX\",\n",
    "    \"DST_TO_SRC_SECOND_BYTES\",\n",
    "    \"DNS_TTL_ANSWER\",\n",
    "    \"NUM_PKTS_1024_TO_1514_BYTES\",\n",
    "    \"SRC_TO_DST_AVG_THROUGHPUT\",\n",
    "    \"DST_TO_SRC_IAT_STDDEV\",\n",
    "    \"OUT_PKTS\",\n",
    "    \"SRC_TO_DST_IAT_MAX\",\n",
    "    \"TCP_WIN_MAX_IN\",\n",
    "    \"MAX_IP_PKT_LEN\",\n",
    "    \"DST_TO_SRC_AVG_THROUGHPUT\",\n",
    "    \"DST_TO_SRC_IAT_MIN\",\n",
    "    \"RETRANSMITTED_IN_BYTES\"\n",
    "\n",
    "    ]\n",
    "\n",
    "categorical_cols = [\n",
    "    \"PROTOCOL\",\n",
    "    \"L7_PROTO\",\n",
    "    \"TCP_FLAGS\",\n",
    "    \"CLIENT_TCP_FLAGS\",\n",
    "    \"SERVER_TCP_FLAGS\",\n",
    "    \"ICMP_TYPE\",\n",
    "    \"ICMP_IPV4_TYPE\",\n",
    "    \"DNS_QUERY_TYPE\",\n",
    "    \"FTP_COMMAND_RET_CODE\"\n",
    "    ]\n",
    "\n",
    "target_col = 'Attack'\n",
    "num_target_classes = 10\n",
    "dataset_path = 'datasets/NF-UNSW-NB15-v3.csv'\n",
    "batch_size = 4096\n",
    "epochs = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9df5c55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, valid_dataloader, test_dataloader, cat_cardinalities, cw, target_names = load_and_prepare_nb15(\n",
    "    file_path=dataset_path,\n",
    "    target_col=target_col,\n",
    "    numerical_cols=numerical_cols,\n",
    "    categorical_cols=categorical_cols,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "embedding_dims = [min(50, (card + 1) // 2) for card in cat_cardinalities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "168e5949",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork(\n",
    "    hidden_layers_sizes=[256, 256, 256], \n",
    "    cat_cardinalities=cat_cardinalities,\n",
    "    embedding_dims=embedding_dims,\n",
    "    num_numerical_features=len(numerical_cols),\n",
    "    num_target_classes=num_target_classes,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8610ff8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "972d3c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e31e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch: 0  |  Loss: 0.0397  |  F1 Score: 0.4062  |  Accuracy: 0.9869 ---\n",
      "--- Epoch: 1  |  Loss: 0.0378  |  F1 Score: 0.4324  |  Accuracy: 0.9873 ---\n",
      "--- Epoch: 2  |  Loss: 0.0369  |  F1 Score: 0.4326  |  Accuracy: 0.9875 ---\n",
      "--- Epoch: 3  |  Loss: 0.0358  |  F1 Score: 0.4874  |  Accuracy: 0.9881 ---\n",
      "--- Epoch: 4  |  Loss: 0.0355  |  F1 Score: 0.5167  |  Accuracy: 0.9880 ---\n",
      "--- Epoch: 5  |  Loss: 0.0353  |  F1 Score: 0.4985  |  Accuracy: 0.9881 ---\n",
      "--- Epoch: 6  |  Loss: 0.0352  |  F1 Score: 0.4995  |  Accuracy: 0.9883 ---\n",
      "--- Epoch: 7  |  Loss: 0.0340  |  F1 Score: 0.5500  |  Accuracy: 0.9888 ---\n",
      "--- Epoch: 8  |  Loss: 0.0338  |  F1 Score: 0.5717  |  Accuracy: 0.9888 ---\n",
      "--- Epoch: 9  |  Loss: 0.0338  |  F1 Score: 0.5725  |  Accuracy: 0.9889 ---\n",
      "--- Epoch: 10  |  Loss: 0.0341  |  F1 Score: 0.5607  |  Accuracy: 0.9887 ---\n",
      "--- Epoch: 11  |  Loss: 0.0339  |  F1 Score: 0.5544  |  Accuracy: 0.9889 ---\n",
      "--- Epoch: 12  |  Loss: 0.0343  |  F1 Score: 0.5772  |  Accuracy: 0.9887 ---\n",
      "--- Epoch: 13  |  Loss: 0.0341  |  F1 Score: 0.5741  |  Accuracy: 0.9889 ---\n",
      "--- Epoch: 14  |  Loss: 0.0345  |  F1 Score: 0.5868  |  Accuracy: 0.9889 ---\n",
      "--- Epoch: 15  |  Loss: 0.0345  |  F1 Score: 0.5732  |  Accuracy: 0.9889 ---\n",
      "--- Epoch: 16  |  Loss: 0.0346  |  F1 Score: 0.5822  |  Accuracy: 0.9889 ---\n",
      "--- Epoch: 17  |  Loss: 0.0347  |  F1 Score: 0.5733  |  Accuracy: 0.9889 ---\n",
      "--- Epoch: 18  |  Loss: 0.0350  |  F1 Score: 0.5777  |  Accuracy: 0.9889 ---\n",
      "--- Epoch: 19  |  Loss: 0.0349  |  F1 Score: 0.5914  |  Accuracy: 0.9889 ---\n",
      "--- Epoch: 20  |  Loss: 0.0353  |  F1 Score: 0.5778  |  Accuracy: 0.9889 ---\n",
      "--- Epoch: 21  |  Loss: 0.0352  |  F1 Score: 0.5823  |  Accuracy: 0.9889 ---\n",
      "--- Epoch: 22  |  Loss: 0.0355  |  F1 Score: 0.5896  |  Accuracy: 0.9889 ---\n",
      "--- Epoch: 23  |  Loss: 0.0357  |  F1 Score: 0.5823  |  Accuracy: 0.9889 ---\n",
      "--- Epoch: 24  |  Loss: 0.0357  |  F1 Score: 0.5962  |  Accuracy: 0.9889 ---\n",
      "--- Epoch: 25  |  Loss: 0.0358  |  F1 Score: 0.6004  |  Accuracy: 0.9890 ---\n",
      "--- Epoch: 26  |  Loss: 0.0360  |  F1 Score: 0.6085  |  Accuracy: 0.9890 ---\n",
      "--- Epoch: 27  |  Loss: 0.0361  |  F1 Score: 0.5942  |  Accuracy: 0.9890 ---\n",
      "--- Epoch: 28  |  Loss: 0.0361  |  F1 Score: 0.5978  |  Accuracy: 0.9889 ---\n",
      "--- Epoch: 29  |  Loss: 0.0363  |  F1 Score: 0.6032  |  Accuracy: 0.9889 ---\n",
      "--- Epoch: 30  |  Loss: 0.0363  |  F1 Score: 0.6073  |  Accuracy: 0.9889 ---\n",
      "--- Epoch: 31  |  Loss: 0.0363  |  F1 Score: 0.6050  |  Accuracy: 0.9890 ---\n",
      "--- Epoch: 32  |  Loss: 0.0364  |  F1 Score: 0.6005  |  Accuracy: 0.9889 ---\n",
      "--- Epoch: 33  |  Loss: 0.0364  |  F1 Score: 0.6063  |  Accuracy: 0.9889 ---\n",
      "--- Epoch: 34  |  Loss: 0.0365  |  F1 Score: 0.6076  |  Accuracy: 0.9889 ---\n",
      "--- Epoch: 35  |  Loss: 0.0365  |  F1 Score: 0.6043  |  Accuracy: 0.9889 ---\n",
      "--- Epoch: 36  |  Loss: 0.0365  |  F1 Score: 0.6046  |  Accuracy: 0.9889 ---\n",
      "--- Epoch: 37  |  Loss: 0.0366  |  F1 Score: 0.6063  |  Accuracy: 0.9889 ---\n",
      "--- Epoch: 38  |  Loss: 0.0367  |  F1 Score: 0.6054  |  Accuracy: 0.9889 ---\n",
      "--- Epoch: 39  |  Loss: 0.0367  |  F1 Score: 0.6054  |  Accuracy: 0.9889 ---\n",
      "--- Epoch: 40  |  Loss: 0.0367  |  F1 Score: 0.6051  |  Accuracy: 0.9889 ---\n",
      "--- Epoch: 41  |  Loss: 0.0368  |  F1 Score: 0.6053  |  Accuracy: 0.9889 ---\n",
      "--- Epoch: 42  |  Loss: 0.0367  |  F1 Score: 0.6055  |  Accuracy: 0.9889 ---\n",
      "--- Epoch: 43  |  Loss: 0.0367  |  F1 Score: 0.6052  |  Accuracy: 0.9889 ---\n",
      "--- Epoch: 44  |  Loss: 0.0368  |  F1 Score: 0.6045  |  Accuracy: 0.9889 ---\n",
      "--- Epoch: 45  |  Loss: 0.0368  |  F1 Score: 0.6039  |  Accuracy: 0.9889 ---\n",
      "--- Epoch: 46  |  Loss: 0.0368  |  F1 Score: 0.6063  |  Accuracy: 0.9889 ---\n",
      "--- Epoch: 47  |  Loss: 0.0368  |  F1 Score: 0.6054  |  Accuracy: 0.9889 ---\n",
      "--- Epoch: 48  |  Loss: 0.0368  |  F1 Score: 0.6058  |  Accuracy: 0.9889 ---\n",
      "--- Epoch: 49  |  Loss: 0.0368  |  F1 Score: 0.6057  |  Accuracy: 0.9889 ---\n",
      "--- Epoch: 50  |  Loss: 0.0368  |  F1 Score: 0.6049  |  Accuracy: 0.9889 ---\n",
      "--- Epoch: 51  |  Loss: 0.0368  |  F1 Score: 0.6055  |  Accuracy: 0.9889 ---\n",
      "--- Epoch: 52  |  Loss: 0.0368  |  F1 Score: 0.6052  |  Accuracy: 0.9889 ---\n",
      "--- Epoch: 53  |  Loss: 0.0369  |  F1 Score: 0.6052  |  Accuracy: 0.9889 ---\n",
      "--- Epoch: 54  |  Loss: 0.0369  |  F1 Score: 0.6049  |  Accuracy: 0.9889 ---\n",
      "--- Epoch: 55  |  Loss: 0.0369  |  F1 Score: 0.6049  |  Accuracy: 0.9889 ---\n",
      "--- Epoch: 56  |  Loss: 0.0369  |  F1 Score: 0.6050  |  Accuracy: 0.9889 ---\n",
      "--- Epoch: 57  |  Loss: 0.0369  |  F1 Score: 0.6050  |  Accuracy: 0.9889 ---\n",
      "--- Epoch: 58  |  Loss: 0.0369  |  F1 Score: 0.6052  |  Accuracy: 0.9889 ---\n",
      "--- Epoch: 59  |  Loss: 0.0369  |  F1 Score: 0.6047  |  Accuracy: 0.9889 ---\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_dataloader=train_dataloader,\n",
    "    valid_dataloader=valid_dataloader,\n",
    "    device=device,\n",
    "    optimizer=optimizer,\n",
    "    lr_scheduler=scheduler,\n",
    "    epochs=epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "371bd972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_optimizer(model, wd=1e-4,\n",
    "                   lr_trunk=1e-3, lr_heads=2e-3, lr_emb=None):\n",
    "    if lr_emb is None:\n",
    "        lr_emb = lr_trunk * 0.5\n",
    "\n",
    "    trunk_params = list(model.fc1.parameters()) + \\\n",
    "                   list(model.fc2.parameters()) + \\\n",
    "                   list(model.fc3.parameters())\n",
    "    heads12_params = list(model.head1.parameters()) + list(model.head2.parameters())\n",
    "    head3_params   = list(model.head3.parameters())\n",
    "\n",
    "    opt = torch.optim.AdamW([\n",
    "        {\"params\": model.embeddings.parameters(), \"lr\": lr_emb},\n",
    "        {\"params\": trunk_params, \"lr\": lr_trunk},\n",
    "        {\"params\": heads12_params, \"lr\": lr_heads},\n",
    "        {\"params\": head3_params, \"lr\": lr_heads},\n",
    "    ], weight_decay=wd)\n",
    "    return opt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0c23df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "branchynet = DenseBranchyNet(\n",
    "    hidden_layers_sizes=[256, 256, 256],\n",
    "    taus=[1.4, 1.6],\n",
    "    alphas=[0.2, 0.8, 0.9],\n",
    "    cat_cardinalities=cat_cardinalities,\n",
    "    embedding_dims=embedding_dims,\n",
    "    num_numerical=len(numerical_cols),\n",
    "    num_target_classes=num_target_classes\n",
    "    ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ee0fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Ep 001] train_loss=0.2059 (l1=0.1846 l2=0.0975 l3=0.1010)  | val_acc=0.9847  val_f1=0.9818\n",
      "[Ep 002] train_loss=0.0860 (l1=0.0643 l2=0.0438 l3=0.0424)  | val_acc=0.9866  val_f1=0.9843\n",
      "[Ep 003] train_loss=0.0789 (l1=0.0555 l2=0.0405 l3=0.0394)  | val_acc=0.9868  val_f1=0.9848\n",
      "[Ep 004] train_loss=0.0754 (l1=0.0516 l2=0.0387 l3=0.0379)  | val_acc=0.9871  val_f1=0.9850\n",
      "[Ep 005] train_loss=0.0730 (l1=0.0490 l2=0.0375 l3=0.0369)  | val_acc=0.9872  val_f1=0.9853\n",
      "[Ep 006] train_loss=0.0712 (l1=0.0473 l2=0.0366 l3=0.0361)  | val_acc=0.9874  val_f1=0.9855\n",
      "[Ep 007] train_loss=0.0697 (l1=0.0459 l2=0.0359 l3=0.0353)  | val_acc=0.9876  val_f1=0.9858\n",
      "[Ep 008] train_loss=0.0685 (l1=0.0448 l2=0.0353 l3=0.0348)  | val_acc=0.9875  val_f1=0.9858\n",
      "[Ep 009] train_loss=0.0675 (l1=0.0440 l2=0.0348 l3=0.0343)  | val_acc=0.9877  val_f1=0.9861\n",
      "[Ep 010] train_loss=0.0668 (l1=0.0433 l2=0.0344 l3=0.0340)  | val_acc=0.9875  val_f1=0.9855\n",
      "[Ep 011] train_loss=0.0657 (l1=0.0426 l2=0.0339 l3=0.0334)  | val_acc=0.9880  val_f1=0.9866\n",
      "[Ep 012] train_loss=0.0651 (l1=0.0421 l2=0.0336 l3=0.0331)  | val_acc=0.9881  val_f1=0.9866\n",
      "[Ep 013] train_loss=0.0644 (l1=0.0417 l2=0.0332 l3=0.0327)  | val_acc=0.9881  val_f1=0.9866\n",
      "[Ep 014] train_loss=0.0637 (l1=0.0413 l2=0.0329 l3=0.0324)  | val_acc=0.9881  val_f1=0.9866\n",
      "[Ep 015] train_loss=0.0617 (l1=0.0409 l2=0.0319 l3=0.0311)  | val_acc=0.9884  val_f1=0.9869\n",
      "[Ep 016] train_loss=0.0611 (l1=0.0406 l2=0.0316 l3=0.0308)  | val_acc=0.9884  val_f1=0.9869\n",
      "[Ep 017] train_loss=0.0609 (l1=0.0405 l2=0.0315 l3=0.0307)  | val_acc=0.9883  val_f1=0.9870\n",
      "[Ep 018] train_loss=0.0604 (l1=0.0403 l2=0.0313 l3=0.0304)  | val_acc=0.9884  val_f1=0.9873\n",
      "[Ep 019] train_loss=0.0602 (l1=0.0402 l2=0.0312 l3=0.0302)  | val_acc=0.9884  val_f1=0.9872\n",
      "[Ep 020] train_loss=0.0600 (l1=0.0400 l2=0.0310 l3=0.0301)  | val_acc=0.9884  val_f1=0.9872\n",
      "[Ep 021] train_loss=0.0595 (l1=0.0399 l2=0.0308 l3=0.0299)  | val_acc=0.9883  val_f1=0.9871\n",
      "[Ep 022] train_loss=0.0584 (l1=0.0397 l2=0.0303 l3=0.0291)  | val_acc=0.9885  val_f1=0.9872\n",
      "[Ep 023] train_loss=0.0581 (l1=0.0396 l2=0.0302 l3=0.0289)  | val_acc=0.9884  val_f1=0.9872\n",
      "[Ep 024] train_loss=0.0579 (l1=0.0396 l2=0.0301 l3=0.0288)  | val_acc=0.9885  val_f1=0.9871\n",
      "[Ep 025] train_loss=0.0572 (l1=0.0395 l2=0.0298 l3=0.0283)  | val_acc=0.9886  val_f1=0.9873\n",
      "[Ep 026] train_loss=0.0570 (l1=0.0394 l2=0.0297 l3=0.0282)  | val_acc=0.9885  val_f1=0.9873\n",
      "[Ep 027] train_loss=0.0569 (l1=0.0394 l2=0.0296 l3=0.0281)  | val_acc=0.9885  val_f1=0.9873\n",
      "[Ep 028] train_loss=0.0565 (l1=0.0394 l2=0.0295 l3=0.0278)  | val_acc=0.9885  val_f1=0.9873\n",
      "[Ep 029] train_loss=0.0565 (l1=0.0394 l2=0.0295 l3=0.0278)  | val_acc=0.9885  val_f1=0.9874\n",
      "[Ep 030] train_loss=0.0564 (l1=0.0394 l2=0.0294 l3=0.0277)  | val_acc=0.9885  val_f1=0.9873\n",
      "[Ep 031] train_loss=0.0564 (l1=0.0394 l2=0.0294 l3=0.0277)  | val_acc=0.9885  val_f1=0.9874\n",
      "[Ep 032] train_loss=0.0563 (l1=0.0393 l2=0.0294 l3=0.0277)  | val_acc=0.9885  val_f1=0.9874\n",
      "[Ep 033] train_loss=0.0561 (l1=0.0393 l2=0.0293 l3=0.0275)  | val_acc=0.9885  val_f1=0.9874\n",
      "[Ep 034] train_loss=0.0561 (l1=0.0393 l2=0.0293 l3=0.0275)  | val_acc=0.9886  val_f1=0.9874\n",
      "[Ep 035] train_loss=0.0560 (l1=0.0393 l2=0.0293 l3=0.0275)  | val_acc=0.9885  val_f1=0.9874\n",
      "[Ep 036] train_loss=0.0559 (l1=0.0393 l2=0.0293 l3=0.0274)  | val_acc=0.9885  val_f1=0.9874\n",
      "[Ep 037] train_loss=0.0559 (l1=0.0393 l2=0.0292 l3=0.0274)  | val_acc=0.9885  val_f1=0.9874\n",
      "[Ep 038] train_loss=0.0559 (l1=0.0393 l2=0.0293 l3=0.0274)  | val_acc=0.9885  val_f1=0.9874\n",
      "[Ep 039] train_loss=0.0558 (l1=0.0393 l2=0.0292 l3=0.0273)  | val_acc=0.9885  val_f1=0.9874\n",
      "[Ep 040] train_loss=0.0558 (l1=0.0393 l2=0.0292 l3=0.0273)  | val_acc=0.9885  val_f1=0.9874\n"
     ]
    }
   ],
   "source": [
    "branchynet.set_stage(\"stage0_trunk_final\")\n",
    "optimizer = make_optimizer(branchynet, lr_trunk=1e-3, lr_heads=2e-3, lr_emb=5e-4)\n",
    "hist0 = branchynet.fit(train_dataloader, valid_dataloader, optimizer, device, epochs=epochs/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766e2059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Ep 001] train_loss=0.0556 (l1=0.0352 l2=0.0300 l3=0.0273)  | val_acc=0.9887  val_f1=0.9877\n",
      "[Ep 002] train_loss=0.0549 (l1=0.0324 l2=0.0298 l3=0.0273)  | val_acc=0.9887  val_f1=0.9878\n",
      "[Ep 003] train_loss=0.0548 (l1=0.0318 l2=0.0298 l3=0.0273)  | val_acc=0.9887  val_f1=0.9878\n",
      "[Ep 004] train_loss=0.0545 (l1=0.0314 l2=0.0296 l3=0.0273)  | val_acc=0.9887  val_f1=0.9878\n",
      "[Ep 005] train_loss=0.0538 (l1=0.0306 l2=0.0289 l3=0.0272)  | val_acc=0.9888  val_f1=0.9878\n",
      "[Ep 006] train_loss=0.0538 (l1=0.0305 l2=0.0289 l3=0.0273)  | val_acc=0.9887  val_f1=0.9878\n",
      "[Ep 007] train_loss=0.0538 (l1=0.0304 l2=0.0290 l3=0.0272)  | val_acc=0.9887  val_f1=0.9878\n",
      "[Ep 008] train_loss=0.0537 (l1=0.0304 l2=0.0289 l3=0.0272)  | val_acc=0.9887  val_f1=0.9878\n",
      "[Ep 009] train_loss=0.0534 (l1=0.0300 l2=0.0286 l3=0.0273)  | val_acc=0.9887  val_f1=0.9878\n",
      "[Ep 010] train_loss=0.0534 (l1=0.0300 l2=0.0286 l3=0.0273)  | val_acc=0.9887  val_f1=0.9878\n",
      "[Ep 011] train_loss=0.0534 (l1=0.0300 l2=0.0286 l3=0.0272)  | val_acc=0.9887  val_f1=0.9878\n",
      "[Ep 012] train_loss=0.0532 (l1=0.0298 l2=0.0284 l3=0.0273)  | val_acc=0.9887  val_f1=0.9878\n",
      "[Ep 013] train_loss=0.0532 (l1=0.0297 l2=0.0284 l3=0.0272)  | val_acc=0.9887  val_f1=0.9878\n",
      "[Ep 014] train_loss=0.0532 (l1=0.0297 l2=0.0284 l3=0.0273)  | val_acc=0.9887  val_f1=0.9878\n",
      "[Ep 015] train_loss=0.0531 (l1=0.0296 l2=0.0283 l3=0.0273)  | val_acc=0.9887  val_f1=0.9878\n",
      "[Ep 016] train_loss=0.0531 (l1=0.0297 l2=0.0283 l3=0.0273)  | val_acc=0.9887  val_f1=0.9878\n",
      "[Ep 017] train_loss=0.0531 (l1=0.0296 l2=0.0283 l3=0.0273)  | val_acc=0.9887  val_f1=0.9878\n",
      "[Ep 018] train_loss=0.0530 (l1=0.0296 l2=0.0282 l3=0.0273)  | val_acc=0.9887  val_f1=0.9878\n",
      "[Ep 019] train_loss=0.0530 (l1=0.0296 l2=0.0282 l3=0.0272)  | val_acc=0.9887  val_f1=0.9878\n",
      "[Ep 020] train_loss=0.0531 (l1=0.0296 l2=0.0282 l3=0.0273)  | val_acc=0.9887  val_f1=0.9878\n"
     ]
    }
   ],
   "source": [
    "branchynet.set_stage(\"stage1_heads_only\")\n",
    "optimizer = make_optimizer(branchynet, lr_trunk=0.0, lr_heads=3e-3, lr_emb=0.0) \n",
    "hist1 = branchynet.fit(train_dataloader, valid_dataloader, optimizer, device, epochs=epochs/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c934d361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Ep 001] train_loss=0.0538 (l1=0.0299 l2=0.0287 l3=0.0277)  | val_acc=0.9888  val_f1=0.9878\n",
      "[Ep 002] train_loss=0.0537 (l1=0.0299 l2=0.0286 l3=0.0276)  | val_acc=0.9887  val_f1=0.9878\n",
      "[Ep 003] train_loss=0.0536 (l1=0.0298 l2=0.0285 l3=0.0276)  | val_acc=0.9887  val_f1=0.9877\n",
      "[Ep 004] train_loss=0.0535 (l1=0.0298 l2=0.0285 l3=0.0275)  | val_acc=0.9887  val_f1=0.9878\n",
      "[Ep 005] train_loss=0.0530 (l1=0.0296 l2=0.0282 l3=0.0273)  | val_acc=0.9887  val_f1=0.9877\n",
      "[Ep 006] train_loss=0.0529 (l1=0.0296 l2=0.0281 l3=0.0272)  | val_acc=0.9887  val_f1=0.9877\n",
      "[Ep 007] train_loss=0.0528 (l1=0.0295 l2=0.0281 l3=0.0272)  | val_acc=0.9887  val_f1=0.9878\n",
      "[Ep 008] train_loss=0.0525 (l1=0.0294 l2=0.0279 l3=0.0271)  | val_acc=0.9887  val_f1=0.9878\n",
      "[Ep 009] train_loss=0.0525 (l1=0.0294 l2=0.0279 l3=0.0270)  | val_acc=0.9887  val_f1=0.9878\n",
      "[Ep 010] train_loss=0.0525 (l1=0.0294 l2=0.0279 l3=0.0270)  | val_acc=0.9887  val_f1=0.9877\n",
      "[Ep 011] train_loss=0.0524 (l1=0.0293 l2=0.0278 l3=0.0270)  | val_acc=0.9887  val_f1=0.9878\n",
      "[Ep 012] train_loss=0.0523 (l1=0.0293 l2=0.0278 l3=0.0269)  | val_acc=0.9887  val_f1=0.9877\n",
      "[Ep 013] train_loss=0.0523 (l1=0.0293 l2=0.0278 l3=0.0269)  | val_acc=0.9887  val_f1=0.9878\n",
      "[Ep 014] train_loss=0.0522 (l1=0.0293 l2=0.0277 l3=0.0269)  | val_acc=0.9887  val_f1=0.9878\n",
      "[Ep 015] train_loss=0.0522 (l1=0.0293 l2=0.0277 l3=0.0269)  | val_acc=0.9887  val_f1=0.9878\n",
      "[Ep 016] train_loss=0.0522 (l1=0.0293 l2=0.0277 l3=0.0269)  | val_acc=0.9887  val_f1=0.9878\n",
      "[Ep 017] train_loss=0.0521 (l1=0.0292 l2=0.0277 l3=0.0268)  | val_acc=0.9887  val_f1=0.9877\n",
      "[Ep 018] train_loss=0.0521 (l1=0.0292 l2=0.0277 l3=0.0268)  | val_acc=0.9887  val_f1=0.9878\n",
      "[Ep 019] train_loss=0.0522 (l1=0.0292 l2=0.0277 l3=0.0269)  | val_acc=0.9887  val_f1=0.9878\n",
      "[Ep 020] train_loss=0.0522 (l1=0.0293 l2=0.0277 l3=0.0268)  | val_acc=0.9887  val_f1=0.9878\n"
     ]
    }
   ],
   "source": [
    "branchynet.set_stage(\"stage2_finetune_all\")\n",
    "optimizer = make_optimizer(branchynet, lr_trunk=1e-4, lr_heads=3e-4, lr_emb=5e-5)\n",
    "hist2 = branchynet.fit(train_dataloader, valid_dataloader, optimizer, device, epochs=epochs/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6a3940e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def measure_stage_costs(model, loader, device, n_batches=5):\n",
    "    model.eval()\n",
    "    if device.type == \"cuda\":\n",
    "        starter = torch.cuda.Event(enable_timing=True); ender = torch.cuda.Event(enable_timing=True)\n",
    "    t1, t12, t123 = [], [], []\n",
    "    for i, (x_num, x_cat, _) in enumerate(loader):\n",
    "        x_num = x_num.to(device, non_blocking=True); x_cat = x_cat.to(device, non_blocking=True).long()\n",
    "        if device.type == \"cuda\": torch.cuda.synchronize()\n",
    "        # c1\n",
    "        if device.type == \"cuda\": starter.record()\n",
    "        x  = model._embed_input(x_num, x_cat)\n",
    "        h1 = F.relu(model.fc1(x)); l1 = model.head1(h1)\n",
    "        if device.type == \"cuda\": ender.record(); torch.cuda.synchronize(); t1.append(starter.elapsed_time(ender)/1000.0)\n",
    "        else: t1.append(0)  # su CPU puoi usare time.perf_counter, ma su GPU è più preciso così\n",
    "        # c1+c2\n",
    "        if device.type == \"cuda\": starter.record()\n",
    "        h2 = F.relu(model.fc2(h1)); l2 = model.head2(h2)\n",
    "        if device.type == \"cuda\": ender.record(); torch.cuda.synchronize(); t12.append(starter.elapsed_time(ender)/1000.0)\n",
    "        # c1+c2+c3\n",
    "        if device.type == \"cuda\": starter.record()\n",
    "        h3 = F.relu(model.fc3(h2)); l3 = model.head3(h3)\n",
    "        if device.type == \"cuda\": ender.record(); torch.cuda.synchronize(); t123.append(starter.elapsed_time(ender)/1000.0)\n",
    "\n",
    "        if i+1 >= n_batches: break\n",
    "\n",
    "    c1 = sum(t1)/len(t1); c12 = sum(t12)/len(t12); c123 = sum(t123)/len(t123)\n",
    "    return {\"c1\": c1, \"c2\": c12 - c1, \"c3\": c123 - c12}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f932a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "τ: [81.59566497802734, 167.44451904296875] F1: 0.9878117999140423 rates: {'r1': 0.005002378020435572, 'r2': 0.004975627176463604, 'r3': 0.9900219948031008} cost_norm: 1.0051191961050954\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def f1_baseline_head3(model, loader, device):\n",
    "    from sklearn.metrics import f1_score\n",
    "    model.eval(); y_true, y_pred = [], []\n",
    "    for x_num, x_cat, y in loader:\n",
    "        x_num = x_num.to(device); x_cat = x_cat.to(device).long()\n",
    "        _, _, out3 = model(x_num, x_cat)\n",
    "        y_true += y.tolist(); y_pred += out3.argmax(1).cpu().tolist()\n",
    "    return f1_score(y_true, y_pred, average=\"weighted\")\n",
    "\n",
    "use_margin = True  # stesso setting di evaluate/predict\n",
    "base_f1 = f1_baseline_head3(branchynet, valid_dataloader, device)\n",
    "cost = measure_stage_costs(branchynet, valid_dataloader, device, n_batches=5)\n",
    "\n",
    "best = branchynet.calibrate_taus(\n",
    "    valid_dataloader, device, use_margin=use_margin,\n",
    "    n_grid=21, mode=\"min_cost_at_f1\",\n",
    "    f1_min=base_f1 - 0.001,                 # es. max -0.1% drop F1\n",
    "    cost=cost\n",
    ")\n",
    "branchynet.taus = [best[\"t1\"], best[\"t2\"]]\n",
    "print(\"τ:\", branchynet.taus, \"F1:\", best[\"f1\"], \"rates:\", best[\"rates\"], \"cost_norm:\", best[\"cost\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "568201fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = torch.cat([y for _, _, y in test_dataloader]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "759b5d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_model = time.time()\n",
    "model_preds = model.predict(test_dataloader,device)\n",
    "end_model = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2a5269",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_branchynet = time.time()\n",
    "branchy_preds = branchynet.predict(test_dataloader, device, early_exit=True, use_margin=use_margin)\n",
    "end_branchynet = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "155649ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classic DNN: 3.020097 s\n",
      "BranchyNet:  3.310293 s\n"
     ]
    }
   ],
   "source": [
    "dur_model   = end_model - start_model\n",
    "dur_branchy = end_branchynet - start_branchynet\n",
    "\n",
    "print(f\"Classic DNN: {dur_model:.6f} s\")\n",
    "print(f\"BranchyNet:  {dur_branchy:.6f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9116521f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BranchyNet Overhead: 8.77%\n"
     ]
    }
   ],
   "source": [
    "overhead = 100 - ((100 / dur_branchy) * dur_model)\n",
    "print(f'BranchyNet Overhead: {overhead:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af7268be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Classification Report DNN===\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Analysis     0.2973    0.2391    0.2651       184\n",
      "      Backdoor     0.3923    0.0986    0.1577       517\n",
      "        Benign     1.0000    1.0000    1.0000    322654\n",
      "           DoS     0.5357    0.1781    0.2673       758\n",
      "      Exploits     0.7816    0.7944    0.7879      5823\n",
      "       Fuzzers     0.6922    0.9403    0.7974      3838\n",
      "       Generic     0.7633    0.6232    0.6862       714\n",
      "Reconnaissance     0.7284    0.5968    0.6561      1694\n",
      "     Shellcode     0.7761    0.4370    0.5591       238\n",
      "         Worms     0.6250    0.7500    0.6818        20\n",
      "\n",
      "      accuracy                         0.9888    336440\n",
      "     macro avg     0.6592    0.5658    0.5859    336440\n",
      "  weighted avg     0.9883    0.9888    0.9879    336440\n",
      "\n",
      "\n",
      "=== Classification Report BRANCHYNET===\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Analysis     0.3309    0.2500    0.2848       184\n",
      "      Backdoor     0.3081    0.1103    0.1624       517\n",
      "        Benign     1.0000    1.0000    1.0000    322654\n",
      "           DoS     0.5000    0.2230    0.3084       758\n",
      "      Exploits     0.7833    0.7889    0.7861      5823\n",
      "       Fuzzers     0.6935    0.9237    0.7922      3838\n",
      "       Generic     0.7940    0.6317    0.7036       714\n",
      "Reconnaissance     0.7170    0.6057    0.6566      1694\n",
      "     Shellcode     0.7710    0.4244    0.5474       238\n",
      "         Worms     0.8333    0.7500    0.7895        20\n",
      "\n",
      "      accuracy                         0.9887    336440\n",
      "     macro avg     0.6731    0.5707    0.6031    336440\n",
      "  weighted avg     0.9881    0.9887    0.9880    336440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Classification Report DNN===\")\n",
    "print(classification_report(y_true, model_preds.numpy(), target_names=target_names, digits=4))\n",
    "print(\"\\n=== Classification Report BRANCHYNET===\")\n",
    "print(classification_report(y_true, branchy_preds.numpy(), target_names=target_names, digits=4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
