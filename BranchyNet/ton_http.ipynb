{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e2c1364",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_and_prepare_data\n",
    "from neural_network import *\n",
    "from dense_branchynet import *\n",
    "import time\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "numerical_cols = [\n",
    "        \"duration\",\n",
    "        \"dst_bytes\",\n",
    "        \"missed_bytes\",\n",
    "        \"src_bytes\",\n",
    "        \"src_ip_bytes\",\n",
    "        \"src_pkts\",\n",
    "        \"dst_pkts\",\n",
    "        \"dst_ip_bytes\",\n",
    "        \"http_request_body_len\",\n",
    "        \"http_response_body_len\"\n",
    "\n",
    "    ]\n",
    "\n",
    "categorical_cols = [\n",
    "        \"proto\",\n",
    "        \"conn_state\",\n",
    "        \"http_status_code\",\n",
    "        \"http_method\",\n",
    "        \"http_orig_mime_types\",\n",
    "        \"http_resp_mime_types\",\n",
    "    ]\n",
    "\n",
    "\n",
    "target_col = 'type'\n",
    "num_target_classes = 8\n",
    "dataset_path = 'datasets/http_ton.csv'\n",
    "batch_size = 2048\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9df5c55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, valid_dataloader, test_dataloader, cat_cardinalities, cw, target_names = load_and_prepare_data(\n",
    "    file_path=dataset_path,\n",
    "    target_col=target_col,\n",
    "    numerical_cols=numerical_cols,\n",
    "    categorical_cols=categorical_cols,\n",
    "    batch_size=batch_size,\n",
    "    rows_to_remove={}\n",
    ")\n",
    "\n",
    "embedding_dims = [min(50, (card + 1) // 2) for card in cat_cardinalities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "168e5949",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork(\n",
    "    hidden_layers_sizes=[256, 256, 256], \n",
    "    cat_cardinalities=cat_cardinalities,\n",
    "    embedding_dims=embedding_dims,\n",
    "    num_numerical_features=len(numerical_cols),\n",
    "    num_target_classes=num_target_classes,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "972d3c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.85, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98e31e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch: 0  |  Loss: 0.6041  |  F1 Score: 0.5374  |  Accuracy: 0.7383 ---\n",
      "--- Epoch: 1  |  Loss: 0.6508  |  F1 Score: 0.6078  |  Accuracy: 0.8669 ---\n",
      "--- Epoch: 2  |  Loss: 0.1581  |  F1 Score: 0.7201  |  Accuracy: 0.9621 ---\n",
      "--- Epoch: 3  |  Loss: 0.1465  |  F1 Score: 0.7324  |  Accuracy: 0.9618 ---\n",
      "--- Epoch: 4  |  Loss: 0.1324  |  F1 Score: 0.7317  |  Accuracy: 0.9662 ---\n",
      "--- Epoch: 5  |  Loss: 0.1547  |  F1 Score: 0.7509  |  Accuracy: 0.9660 ---\n",
      "--- Epoch: 6  |  Loss: 0.2331  |  F1 Score: 0.7300  |  Accuracy: 0.9645 ---\n",
      "--- Epoch: 7  |  Loss: 0.1963  |  F1 Score: 0.7416  |  Accuracy: 0.9650 ---\n",
      "--- Epoch: 8  |  Loss: 0.1678  |  F1 Score: 0.7037  |  Accuracy: 0.9646 ---\n",
      "--- Epoch: 9  |  Loss: 0.2172  |  F1 Score: 0.7401  |  Accuracy: 0.9652 ---\n",
      "--- Epoch: 10  |  Loss: 0.2624  |  F1 Score: 0.6573  |  Accuracy: 0.9233 ---\n",
      "--- Epoch: 11  |  Loss: 0.1312  |  F1 Score: 0.7165  |  Accuracy: 0.9835 ---\n",
      "--- Epoch: 12  |  Loss: 0.1390  |  F1 Score: 0.7618  |  Accuracy: 0.9825 ---\n",
      "--- Epoch: 13  |  Loss: 0.1884  |  F1 Score: 0.6868  |  Accuracy: 0.9696 ---\n",
      "--- Epoch: 14  |  Loss: 0.1213  |  F1 Score: 0.7623  |  Accuracy: 0.9838 ---\n",
      "--- Epoch: 15  |  Loss: 0.1582  |  F1 Score: 0.7516  |  Accuracy: 0.9734 ---\n",
      "--- Epoch: 16  |  Loss: 0.1192  |  F1 Score: 0.7683  |  Accuracy: 0.9847 ---\n",
      "--- Epoch: 17  |  Loss: 0.1033  |  F1 Score: 0.7665  |  Accuracy: 0.9849 ---\n",
      "--- Epoch: 18  |  Loss: 0.0909  |  F1 Score: 0.7684  |  Accuracy: 0.9870 ---\n",
      "--- Epoch: 19  |  Loss: 0.1471  |  F1 Score: 0.7748  |  Accuracy: 0.9884 ---\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_dataloader=train_dataloader,\n",
    "    valid_dataloader=valid_dataloader,\n",
    "    device=device,\n",
    "    optimizer=optimizer,\n",
    "    lr_scheduler=scheduler,\n",
    "    epochs=epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0196972f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_optimizer(model, wd=1e-4,\n",
    "                   lr_trunk=1e-3, lr_heads=2e-3, lr_emb=None):\n",
    "    if lr_emb is None:\n",
    "        lr_emb = lr_trunk * 0.5\n",
    "\n",
    "    trunk_params = list(model.fc1.parameters()) + \\\n",
    "                   list(model.fc2.parameters()) + \\\n",
    "                   list(model.fc3.parameters())\n",
    "    heads12_params = list(model.head1.parameters()) + list(model.head2.parameters())\n",
    "    head3_params   = list(model.head3.parameters())\n",
    "\n",
    "    opt = torch.optim.AdamW([\n",
    "        {\"params\": model.embeddings.parameters(), \"lr\": lr_emb},\n",
    "        {\"params\": trunk_params, \"lr\": lr_trunk},\n",
    "        {\"params\": heads12_params, \"lr\": lr_heads},\n",
    "        {\"params\": head3_params, \"lr\": lr_heads},\n",
    "    ], weight_decay=wd)\n",
    "    return opt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0c23df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "branchynet = DenseBranchyNet(\n",
    "    hidden_layers_sizes=[256, 256, 256],\n",
    "    taus=[1.4, 1.6],\n",
    "    alphas=[0.2, 0.8, 0.9],\n",
    "    cat_cardinalities=cat_cardinalities,\n",
    "    embedding_dims=embedding_dims,\n",
    "    num_numerical=len(numerical_cols),\n",
    "    num_target_classes=num_target_classes\n",
    "    ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88ee0fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Ep 001] train_loss=1.4338 (l1=1.3430 l2=0.8546 l3=0.5350)  | val_acc=0.9251  val_f1=0.9169\n",
      "[Ep 002] train_loss=0.9660 (l1=1.2144 l2=0.6479 l3=0.2275)  | val_acc=0.9240  val_f1=0.9200\n",
      "[Ep 003] train_loss=0.8119 (l1=1.1535 l2=0.5337 l3=0.1713)  | val_acc=0.9387  val_f1=0.9335\n",
      "[Ep 004] train_loss=0.7157 (l1=1.1067 l2=0.4525 l3=0.1472)  | val_acc=0.9518  val_f1=0.9483\n",
      "[Ep 005] train_loss=0.6517 (l1=1.0694 l2=0.3915 l3=0.1385)  | val_acc=0.8792  val_f1=0.8769\n",
      "[Ep 006] train_loss=0.5862 (l1=1.0373 l2=0.3417 l3=0.1171)  | val_acc=0.9625  val_f1=0.9592\n",
      "[Ep 007] train_loss=0.5938 (l1=1.0134 l2=0.3292 l3=0.1419)  | val_acc=0.9635  val_f1=0.9604\n",
      "[Ep 008] train_loss=0.5772 (l1=0.9943 l2=0.3177 l3=0.1380)  | val_acc=0.9549  val_f1=0.9520\n",
      "[Ep 009] train_loss=0.5361 (l1=0.9742 l2=0.2961 l3=0.1160)  | val_acc=0.9626  val_f1=0.9603\n",
      "[Ep 010] train_loss=0.5194 (l1=0.9570 l2=0.2746 l3=0.1204)  | val_acc=0.9656  val_f1=0.9640\n"
     ]
    }
   ],
   "source": [
    "branchynet.set_stage(\"stage0_trunk_final\")\n",
    "optimizer = make_optimizer(branchynet, lr_trunk=1e-3, lr_heads=2e-3, lr_emb=5e-4)\n",
    "hist0 = branchynet.fit(train_dataloader, valid_dataloader, optimizer, device, epochs=epochs//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76b79953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Ep 001] train_loss=0.3172 (l1=0.4326 l2=0.1659 l3=0.1089)  | val_acc=0.9613  val_f1=0.9583\n",
      "[Ep 002] train_loss=0.2682 (l1=0.3016 l2=0.1374 l3=0.1088)  | val_acc=0.9639  val_f1=0.9618\n",
      "[Ep 003] train_loss=0.2574 (l1=0.2673 l2=0.1326 l3=0.1088)  | val_acc=0.9623  val_f1=0.9594\n",
      "[Ep 004] train_loss=0.2478 (l1=0.2476 l2=0.1254 l3=0.1088)  | val_acc=0.9630  val_f1=0.9609\n",
      "[Ep 005] train_loss=0.2433 (l1=0.2340 l2=0.1233 l3=0.1088)  | val_acc=0.9646  val_f1=0.9626\n",
      "[Ep 006] train_loss=0.2391 (l1=0.2242 l2=0.1205 l3=0.1088)  | val_acc=0.9643  val_f1=0.9623\n",
      "[Ep 007] train_loss=0.2361 (l1=0.2163 l2=0.1186 l3=0.1088)  | val_acc=0.9643  val_f1=0.9622\n",
      "[Ep 008] train_loss=0.2349 (l1=0.2097 l2=0.1188 l3=0.1088)  | val_acc=0.9642  val_f1=0.9620\n",
      "[Ep 009] train_loss=0.2306 (l1=0.2047 l2=0.1148 l3=0.1088)  | val_acc=0.9650  val_f1=0.9632\n",
      "[Ep 010] train_loss=0.2294 (l1=0.2021 l2=0.1137 l3=0.1088)  | val_acc=0.9649  val_f1=0.9630\n"
     ]
    }
   ],
   "source": [
    "branchynet.set_stage(\"stage1_heads_only\")\n",
    "optimizer = make_optimizer(branchynet, lr_trunk=0.0, lr_heads=3e-3, lr_emb=0.0) \n",
    "hist1 = branchynet.fit(train_dataloader, valid_dataloader, optimizer, device, epochs=epochs//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de49a932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Ep 001] train_loss=0.2110 (l1=0.1961 l2=0.1074 l3=0.0954)  | val_acc=0.9671  val_f1=0.9651\n",
      "[Ep 002] train_loss=0.1983 (l1=0.1937 l2=0.1026 l3=0.0861)  | val_acc=0.9683  val_f1=0.9666\n",
      "[Ep 003] train_loss=0.1907 (l1=0.1918 l2=0.0994 l3=0.0808)  | val_acc=0.9683  val_f1=0.9666\n",
      "[Ep 004] train_loss=0.1840 (l1=0.1901 l2=0.0965 l3=0.0764)  | val_acc=0.9687  val_f1=0.9670\n",
      "[Ep 005] train_loss=0.1791 (l1=0.1884 l2=0.0942 l3=0.0734)  | val_acc=0.9698  val_f1=0.9681\n",
      "[Ep 006] train_loss=0.1740 (l1=0.1866 l2=0.0915 l3=0.0705)  | val_acc=0.9702  val_f1=0.9684\n",
      "[Ep 007] train_loss=0.1698 (l1=0.1851 l2=0.0894 l3=0.0681)  | val_acc=0.9702  val_f1=0.9685\n",
      "[Ep 008] train_loss=0.1656 (l1=0.1834 l2=0.0873 l3=0.0656)  | val_acc=0.9711  val_f1=0.9694\n",
      "[Ep 009] train_loss=0.1623 (l1=0.1820 l2=0.0859 l3=0.0636)  | val_acc=0.9708  val_f1=0.9691\n",
      "[Ep 010] train_loss=0.1585 (l1=0.1806 l2=0.0839 l3=0.0614)  | val_acc=0.9717  val_f1=0.9700\n"
     ]
    }
   ],
   "source": [
    "branchynet.set_stage(\"stage2_finetune_all\")\n",
    "optimizer = make_optimizer(branchynet, lr_trunk=1e-4, lr_heads=3e-4, lr_emb=5e-5)\n",
    "hist2 = branchynet.fit(train_dataloader, valid_dataloader, optimizer, device, epochs=epochs//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a10c884",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def measure_stage_costs(model, loader, device, n_batches=5, warmup=1):\n",
    "    \"\"\"\n",
    "    Misura i tempi medi dei tre stadi:\n",
    "      c1   = embed + fc1 + head1\n",
    "      c2   = (fc2 + head2) incrementale (cioè oltre c1)\n",
    "      c3   = (fc3 + head3) incrementale (cioè oltre c1+c2)\n",
    "    Ritorna: dict {\"c1\": ..., \"c2\": ..., \"c3\": ...} in secondi.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # Timer containers\n",
    "    t_c1, t_c12, t_c123 = [], [], []\n",
    "\n",
    "    # Limita n_batches a quello che c'è davvero\n",
    "    max_batches = min(n_batches + warmup, len(loader)) if hasattr(loader, \"__len__\") else n_batches + warmup\n",
    "    batches_done = 0\n",
    "\n",
    "    # Utility per timing\n",
    "    use_cuda = (device.type == \"cuda\")\n",
    "\n",
    "    if use_cuda:\n",
    "        starter = torch.cuda.Event(enable_timing=True)\n",
    "        ender   = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "    for i, (x_num, x_cat, _) in enumerate(loader):\n",
    "        if batches_done >= max_batches:\n",
    "            break\n",
    "\n",
    "        x_num = x_num.to(device, non_blocking=True)\n",
    "        x_cat = x_cat.to(device, non_blocking=True).long()\n",
    "\n",
    "        # --- C1 ---\n",
    "        if use_cuda:\n",
    "            torch.cuda.synchronize()\n",
    "            starter.record()\n",
    "            x  = model._embed_input(x_num, x_cat)\n",
    "            h1 = F.relu(model.fc1(x)); l1 = model.head1(h1)\n",
    "            ender.record(); torch.cuda.synchronize()\n",
    "            c1 = starter.elapsed_time(ender) / 1000.0\n",
    "        else:\n",
    "            t0 = time.perf_counter()\n",
    "            x  = model._embed_input(x_num, x_cat)\n",
    "            h1 = F.relu(model.fc1(x)); l1 = model.head1(h1)\n",
    "            c1 = time.perf_counter() - t0\n",
    "\n",
    "        # --- C1 + C2 ---\n",
    "        if use_cuda:\n",
    "            starter.record()\n",
    "            h2 = F.relu(model.fc2(h1)); l2 = model.head2(h2)\n",
    "            ender.record(); torch.cuda.synchronize()\n",
    "            c12 = starter.elapsed_time(ender) / 1000.0 + c1\n",
    "        else:\n",
    "            t1 = time.perf_counter()\n",
    "            h2 = F.relu(model.fc2(h1)); l2 = model.head2(h2)\n",
    "            c12 = (time.perf_counter() - t1) + c1\n",
    "\n",
    "        # --- C1 + C2 + C3 ---\n",
    "        if use_cuda:\n",
    "            starter.record()\n",
    "            h3 = F.relu(model.fc3(h2)); l3 = model.head3(h3)\n",
    "            ender.record(); torch.cuda.synchronize()\n",
    "            c123 = starter.elapsed_time(ender) / 1000.0 + c12\n",
    "        else:\n",
    "            t2 = time.perf_counter()\n",
    "            h3 = F.relu(model.fc3(h2)); l3 = model.head3(h3)\n",
    "            c123 = (time.perf_counter() - t2) + c12\n",
    "\n",
    "        # Salta i warm-up\n",
    "        if i >= warmup:\n",
    "            t_c1.append(c1)\n",
    "            t_c12.append(c12)\n",
    "            t_c123.append(c123)\n",
    "\n",
    "        batches_done += 1\n",
    "\n",
    "    if len(t_c1) == 0:\n",
    "        raise RuntimeError(\"measure_stage_costs: nessun batch misurato (loader troppo corto?)\")\n",
    "\n",
    "    c1   = sum(t_c1)  / len(t_c1)\n",
    "    c12  = sum(t_c12) / len(t_c12)\n",
    "    c123 = sum(t_c123)/ len(t_c123)\n",
    "\n",
    "    # tempi incrementali\n",
    "    return {\"c1\": c1, \"c2\": max(1e-9, c12 - c1), \"c3\": max(1e-9, c123 - c12)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "568201fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "τ: [3.703824996948242, 4.516445159912109] F1: 0.9817587132513133 rates: {'r1': 0.5, 'r2': 0.25, 'r3': 0.25} cost_norm: 0.5165398151965035\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def f1_baseline_head3(model, loader, device):\n",
    "    from sklearn.metrics import f1_score\n",
    "    model.eval(); y_true, y_pred = [], []\n",
    "    for x_num, x_cat, y in loader:\n",
    "        x_num = x_num.to(device); x_cat = x_cat.to(device).long()\n",
    "        _, _, out3 = model(x_num, x_cat)\n",
    "        y_true += y.tolist(); y_pred += out3.argmax(1).cpu().tolist()\n",
    "    return f1_score(y_true, y_pred, average=\"weighted\")\n",
    "\n",
    "use_margin = True  # stesso setting di evaluate/predict\n",
    "base_f1 = f1_baseline_head3(branchynet, valid_dataloader, device)\n",
    "cost = measure_stage_costs(branchynet, valid_dataloader, device, n_batches=5)\n",
    "\n",
    "best = branchynet.calibrate_taus(\n",
    "    valid_dataloader, device, use_margin=use_margin,\n",
    "    n_grid=21, mode=\"min_cost_at_f1\",\n",
    "    f1_min=base_f1 - 0.01,                 # es. max -1% drop F1\n",
    "    cost=cost\n",
    ")\n",
    "branchynet.taus = [best[\"t1\"], best[\"t2\"]]\n",
    "print(\"τ:\", branchynet.taus, \"F1:\", best[\"f1\"], \"rates:\", best[\"rates\"], \"cost_norm:\", best[\"cost\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c3c0041",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = torch.cat([y for _, _, y in test_dataloader]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "759b5d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_model = time.time()\n",
    "model_preds = model.predict(test_dataloader,device)\n",
    "end_model = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8c2a5269",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_branchynet = time.time()\n",
    "branchy_preds = branchynet.predict(test_dataloader, device, early_exit=True, use_margin=use_margin)\n",
    "end_branchynet = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "155649ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classic DNN: 6.849227 s\n",
      "BranchyMLP:  5.452931 s\n"
     ]
    }
   ],
   "source": [
    "dur_model   = end_model - start_model\n",
    "dur_branchy = end_branchynet - start_branchynet\n",
    "\n",
    "print(f\"Classic DNN: {dur_model:.6f} s\")\n",
    "print(f\"BranchyMLP:  {dur_branchy:.6f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7a57f2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BranchyNet Overhead: -25.61%\n"
     ]
    }
   ],
   "source": [
    "overhead = 100 - ((100 / dur_branchy) * dur_model)\n",
    "print(f'BranchyNet Overhead: {overhead:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af7268be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Classification Report DNN===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ddos     0.9878    0.9845    0.9862     50614\n",
      "         dos     0.2125    0.6538    0.3208        26\n",
      "   injection     0.9702    0.9674    0.9688     50968\n",
      "        mitm     0.0000    0.0000    0.0000         7\n",
      "      normal     0.9339    0.9426    0.9382      9197\n",
      "    password     0.9919    0.9944    0.9932    189474\n",
      "    scanning     0.9923    0.9304    0.9604      4686\n",
      "         xss     0.9929    0.9929    0.9929    211140\n",
      "\n",
      "    accuracy                         0.9886    516112\n",
      "   macro avg     0.7602    0.8083    0.7700    516112\n",
      "weighted avg     0.9887    0.9886    0.9886    516112\n",
      "\n",
      "\n",
      "=== Classification Report BRANCHYNET===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ddos     0.9761    0.9806    0.9784     50614\n",
      "         dos     0.2609    0.6923    0.3789        26\n",
      "   injection     0.9517    0.9582    0.9549     50968\n",
      "        mitm     0.0000    0.0000    0.0000         7\n",
      "      normal     0.9912    0.7994    0.8850      9197\n",
      "    password     0.9831    0.9967    0.9899    189474\n",
      "    scanning     0.9911    0.9319    0.9606      4686\n",
      "         xss     0.9904    0.9849    0.9876    211140\n",
      "\n",
      "    accuracy                         0.9824    516112\n",
      "   macro avg     0.7681    0.7930    0.7669    516112\n",
      "weighted avg     0.9825    0.9824    0.9822    516112\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mat-rib/Documents/tabular_dnn/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/mat-rib/Documents/tabular_dnn/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/mat-rib/Documents/tabular_dnn/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/mat-rib/Documents/tabular_dnn/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/mat-rib/Documents/tabular_dnn/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/mat-rib/Documents/tabular_dnn/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Classification Report DNN===\")\n",
    "print(classification_report(y_true, model_preds.numpy(), target_names=target_names, digits=4))\n",
    "print(\"\\n=== Classification Report BRANCHYNET===\")\n",
    "print(classification_report(y_true, branchy_preds.numpy(), target_names=target_names, digits=4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
