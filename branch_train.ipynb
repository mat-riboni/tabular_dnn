{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5722b5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from branch_utils import *\n",
    "from neural_network import NeuralNetwork\n",
    "import torch, time\n",
    "from sklearn.metrics import classification_report, confusion_matrix, silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from branches import *\n",
    "from utils import load_data\n",
    "\n",
    "\n",
    "dataset_path = './Dataset/NF-UNSW-NB15-v3.csv'\n",
    "\n",
    "numerical_cols = [\n",
    "    \"NUM_PKTS_128_TO_256_BYTES\",\n",
    "    \"RETRANSMITTED_OUT_PKTS\",\n",
    "    \"SRC_TO_DST_IAT_STDDEV\",\n",
    "    \"SRC_TO_DST_SECOND_BYTES\",\n",
    "    \"IN_PKTS\",\n",
    "    \"LONGEST_FLOW_PKT\",\n",
    "    \"NUM_PKTS_256_TO_512_BYTES\",\n",
    "    \"DST_TO_SRC_IAT_AVG\",\n",
    "    \"OUT_BYTES\",\n",
    "    \"NUM_PKTS_UP_TO_128_BYTES\",\n",
    "    \"DURATION_OUT\",\n",
    "    \"NUM_PKTS_512_TO_1024_BYTES\",\n",
    "    \"SRC_TO_DST_IAT_AVG\",\n",
    "    \"DURATION_IN\",\n",
    "    \"SHORTEST_FLOW_PKT\",\n",
    "    \"RETRANSMITTED_IN_PKTS\",\n",
    "    \"FLOW_DURATION_MILLISECONDS\",\n",
    "    \"IN_BYTES\",\n",
    "    \"MIN_IP_PKT_LEN\",\n",
    "    \"TCP_WIN_MAX_OUT\",\n",
    "    \"SRC_TO_DST_IAT_MIN\",\n",
    "    \"RETRANSMITTED_OUT_BYTES\",\n",
    "    \"DST_TO_SRC_IAT_MAX\",\n",
    "    \"DST_TO_SRC_SECOND_BYTES\",\n",
    "    \"DNS_TTL_ANSWER\",\n",
    "    \"NUM_PKTS_1024_TO_1514_BYTES\",\n",
    "    \"SRC_TO_DST_AVG_THROUGHPUT\",\n",
    "    \"DST_TO_SRC_IAT_STDDEV\",\n",
    "    \"OUT_PKTS\",\n",
    "    \"SRC_TO_DST_IAT_MAX\",\n",
    "    \"TCP_WIN_MAX_IN\",\n",
    "    \"MAX_IP_PKT_LEN\",\n",
    "    \"DST_TO_SRC_AVG_THROUGHPUT\",\n",
    "    \"DST_TO_SRC_IAT_MIN\",\n",
    "    \"RETRANSMITTED_IN_BYTES\"\n",
    "\n",
    "    ]\n",
    "\n",
    "categorical_cols = [\n",
    "    \"PROTOCOL\",\n",
    "    \"L7_PROTO\",\n",
    "    \"TCP_FLAGS\",\n",
    "    \"CLIENT_TCP_FLAGS\",\n",
    "    \"SERVER_TCP_FLAGS\",\n",
    "    \"ICMP_TYPE\",\n",
    "    \"ICMP_IPV4_TYPE\",\n",
    "    \"DNS_QUERY_TYPE\",\n",
    "    \"FTP_COMMAND_RET_CODE\"\n",
    "    ]\n",
    "\n",
    "target_col = 'Attack'\n",
    "model_name = 'branchy_NB15'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 4096\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56bb3d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_included = ['Benign', 'Worms']\n",
    "root_groups = [['DoS', 'Analysis'], ['Backdoor', 'Fuzzers', 'Exploits', 'Generic', 'Reconnaissance', 'Shellcode']] # Classifica Benign e Worms\n",
    "node_1_groups = [] # Classifica DoS e Analytics\n",
    "node_1_included = ['DoS', 'Analysis']\n",
    "node_2_groups = [['Backdoor', 'Fuzzers'], ['Generic', 'Reconnaissance', 'Shellcode']] # Classifica Exploits\n",
    "node_2_included = ['Exploits']\n",
    "node_21_groups = [] # Classifica Backdoor e Fuzzers\n",
    "node_21_included = ['Backdoor', 'Fuzzers']\n",
    "node_22_groups = [] # Classifica Genric, Reconnaissance e Shellcode\n",
    "node_22_included = ['Generic', 'Reconnaissance', 'Shellcode']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9ee225a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa0dca6",
   "metadata": {},
   "source": [
    "### Root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5eae567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Benign', 'Worms', 'group_0', 'group_1']\n"
     ]
    }
   ],
   "source": [
    "root_train_dataloader, root_valid_dataloader, root_test_dataloader, root_cat_cardinalities, root_cw, root_class_names, enc, scaler = prepare_dl_nb15_branching(\n",
    "    data=data,\n",
    "    target_col=target_col,\n",
    "    numerical_cols=numerical_cols,\n",
    "    categorical_cols=categorical_cols,\n",
    "    batch_size=4096,\n",
    "    groups=root_groups\n",
    ")\n",
    "\n",
    "print(root_class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f6211a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = RawEmbedder(\n",
    "    numeric_dim=len(numerical_cols),\n",
    "    cat_cardinalities=root_cat_cardinalities,\n",
    "    embed_dims=[min(50, (card + 1) // 2) for card in root_cat_cardinalities]\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0b322dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Node(in_dim=embedder.out_dim ,hidden=256, n_classes=len(root_class_names), tau={0 : 0.99, 1 : 0.89, 2 : 0, 3 : 0}, embedder=embedder).to(device)\n",
    "root_train_dataloader = flatten_dl(dataloader=root_train_dataloader, chain_node=[root], embedder=embedder, batch_size=batch_size, device=device)\n",
    "root_valid_dataloader = flatten_dl(dataloader=root_valid_dataloader, chain_node=[root], embedder=embedder, batch_size=batch_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86dd4cd",
   "metadata": {},
   "source": [
    "### Node 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f070f71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Analysis', 'DoS']\n"
     ]
    }
   ],
   "source": [
    "node_1_train_dataloader, node_1_valid_dataloader, node_1_test_dataloader, node_1_cat_cardinalities, node_1_cw, node_1_class_names, enc, scaler = prepare_dl_nb15_branching(\n",
    "    data=data,\n",
    "    target_col=target_col,\n",
    "    numerical_cols=numerical_cols,\n",
    "    categorical_cols=categorical_cols,\n",
    "    batch_size=4096,\n",
    "    groups=node_1_groups,\n",
    "    include_classes=node_1_included,\n",
    "    remove_classes=root_included + node_2_groups[0] + node_2_groups[1]\n",
    ")\n",
    "\n",
    "print(node_1_class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b32f4d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_1 = Node(256, 128, n_classes=len(node_1_class_names), tau={0 : 0, 1 : 0}).to(device)\n",
    "node_1_train_dataloader = flatten_dl(dataloader=node_1_train_dataloader, chain_node=[root, node_1], batch_size=batch_size, device=device)\n",
    "node_1_valid_dataloader = flatten_dl(dataloader=node_1_valid_dataloader, chain_node=[root, node_1], batch_size=batch_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7cdba7",
   "metadata": {},
   "source": [
    "### Node 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "538859f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Exploits', 'group_0', 'group_1']\n"
     ]
    }
   ],
   "source": [
    "node_2_train_dataloader, node_2_valid_dataloader, node_2_test_dataloader, node_2_cat_cardinalities, node_2_cw, node_2_class_names, enc, scaler = prepare_dl_nb15_branching(\n",
    "    data=data,\n",
    "    target_col=target_col,\n",
    "    numerical_cols=numerical_cols,\n",
    "    categorical_cols=categorical_cols,\n",
    "    batch_size=4096,\n",
    "    groups=node_2_groups,\n",
    "    include_classes=node_2_included,\n",
    "    remove_classes=root_included + node_1_included\n",
    ")\n",
    "\n",
    "print(node_2_class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d37036d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_2 = Node(256, 128, n_classes=len(node_2_class_names), tau={0:0.8, 1:0, 2:0}).to(device)\n",
    "node_2_train_dataloader = flatten_dl(dataloader=node_2_train_dataloader, chain_node=[root, node_2], batch_size=batch_size, device=device)\n",
    "node_2_valid_dataloader = flatten_dl(dataloader=node_2_valid_dataloader, chain_node=[root, node_2], batch_size=batch_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5816e866",
   "metadata": {},
   "source": [
    "#### Node 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "affdb713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Backdoor', 'Fuzzers']\n"
     ]
    }
   ],
   "source": [
    "node_21_train_dataloader, node_21_valid_dataloader, node_21_test_dataloader, node_21_cat_cardinalities, node_21_cw, node_21_class_names, enc, scaler = prepare_dl_nb15_branching(\n",
    "    data=data,\n",
    "    target_col=target_col,\n",
    "    numerical_cols=numerical_cols,\n",
    "    categorical_cols=categorical_cols,\n",
    "    batch_size=4096,\n",
    "    groups=node_21_groups,\n",
    "    include_classes=node_21_included,\n",
    "    remove_classes=root_included + node_1_included + node_22_included\n",
    ")\n",
    "\n",
    "print(node_21_class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d57f611b",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_21 = Node(128, 64, n_classes=len(node_21_class_names), tau={0:0, 1:0}).to(device)\n",
    "node_21_train_dataloader = flatten_dl(dataloader=node_21_train_dataloader, chain_node=[root, node_2, node_21], batch_size=batch_size, device=device)\n",
    "node_21_valid_dataloader = flatten_dl(dataloader=node_21_valid_dataloader, chain_node=[root, node_2, node_21], batch_size=batch_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9feef09a",
   "metadata": {},
   "source": [
    "### Node 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77aba83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Generic', 'Reconnaissance', 'Shellcode']\n"
     ]
    }
   ],
   "source": [
    "node_22_train_dataloader, node_22_valid_dataloader, node_22_test_dataloader, node_22_cat_cardinalities, node_22_cw, node_22_class_names, enc, scaler = prepare_dl_nb15_branching(\n",
    "    data=data,\n",
    "    target_col=target_col,\n",
    "    numerical_cols=numerical_cols,\n",
    "    categorical_cols=categorical_cols,\n",
    "    batch_size=4096,\n",
    "    groups=node_22_groups,\n",
    "    include_classes=node_22_included,\n",
    "    remove_classes= root_included + node_1_included + node_21_included\n",
    ")\n",
    "\n",
    "print(node_22_class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b52a8fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_22 = Node(128, 64, n_classes=len(node_22_class_names), tau={0:0, 1:0, 2:0}).to(device)\n",
    "node_22_train_dataloader = flatten_dl(dataloader=node_22_train_dataloader, chain_node=[root, node_2, node_22], batch_size=batch_size, device=device)\n",
    "node_22_valid_dataloader = flatten_dl(dataloader=node_22_valid_dataloader, chain_node=[root, node_2, node_22], batch_size=batch_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3902ab",
   "metadata": {},
   "source": [
    "### Creo l'albero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45d7372e",
   "metadata": {},
   "outputs": [],
   "source": [
    "root.add_child(class_idx=2, child=node_1)\n",
    "root.add_child(class_idx=3, child=node_2)\n",
    "node_2.add_child(class_idx=1, child=node_21)\n",
    "node_2.add_child(class_idx=2, child=node_22)\n",
    "\n",
    "nodes = [root, node_1, node_2, node_21, node_22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80b5d76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_node(node, dl_train, dl_val, cw, epochs=8, lr=1e-3):\n",
    "    \"\"\"Allena un singolo nodo (routing OFF)\"\"\"\n",
    "    params = list(node.parameters())\n",
    "    opt = torch.optim.AdamW(params, lr=lr)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss(weight=cw.to(device))\n",
    "    node.fit(dl_train, dl_val, epochs,\n",
    "             optimizer=opt, loss_fn=loss_fn, device=device)\n",
    "    node.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42a72953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training ROOT\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m==> Training ROOT\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mtrain_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdl_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mroot_train_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdl_val\u001b[49m\u001b[43m=\u001b[49m\u001b[43mroot_valid_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcw\u001b[49m\u001b[43m=\u001b[49m\u001b[43mroot_cw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m embedder.parameters(): p.requires_grad = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m==> Training Node 1\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mtrain_node\u001b[39m\u001b[34m(node, dl_train, dl_val, cw, epochs, lr)\u001b[39m\n\u001b[32m      4\u001b[39m opt = torch.optim.AdamW(params, lr=lr)\n\u001b[32m      5\u001b[39m loss_fn = torch.nn.CrossEntropyLoss(weight=cw.to(device))\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mnode\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdl_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdl_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m         \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m node.freeze()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/tesi_triennale/tabular_dnn/branches.py:131\u001b[39m, in \u001b[36mNode.fit\u001b[39m\u001b[34m(self, train_loader, val_loader, epochs, optimizer, loss_fn, device, lr)\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ep \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[32m    130\u001b[39m     \u001b[38;5;28mself\u001b[39m.train()\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/tesi_triennale/tabular_dnn/venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/tesi_triennale/tabular_dnn/venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:789\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    788\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    790\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    791\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/tesi_triennale/tabular_dnn/venv/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/tesi_triennale/tabular_dnn/venv/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:398\u001b[39m, in \u001b[36mdefault_collate\u001b[39m\u001b[34m(batch)\u001b[39m\n\u001b[32m    337\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdefault_collate\u001b[39m(batch):\n\u001b[32m    338\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    339\u001b[39m \u001b[33;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[32m    340\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    396\u001b[39m \u001b[33;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[32m    397\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/tesi_triennale/tabular_dnn/venv/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:212\u001b[39m, in \u001b[36mcollate\u001b[39m\u001b[34m(batch, collate_fn_map)\u001b[39m\n\u001b[32m    208\u001b[39m transposed = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(*batch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m         \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    213\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed\n\u001b[32m    214\u001b[39m     ]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/tesi_triennale/tabular_dnn/venv/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:155\u001b[39m, in \u001b[36mcollate\u001b[39m\u001b[34m(batch, collate_fn_map)\u001b[39m\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/tesi_triennale/tabular_dnn/venv/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:272\u001b[39m, in \u001b[36mcollate_tensor_fn\u001b[39m\u001b[34m(batch, collate_fn_map)\u001b[39m\n\u001b[32m    270\u001b[39m     storage = elem._typed_storage()._new_shared(numel, device=elem.device)\n\u001b[32m    271\u001b[39m     out = elem.new(storage).resize_(\u001b[38;5;28mlen\u001b[39m(batch), *\u001b[38;5;28mlist\u001b[39m(elem.size()))\n\u001b[32m--> \u001b[39m\u001b[32m272\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "print(\"==> Training ROOT\")\n",
    "train_node(node=root, dl_train=root_train_dataloader, dl_val=root_valid_dataloader, cw=root_cw, epochs=10)\n",
    "for p in embedder.parameters(): p.requires_grad = False\n",
    "\n",
    "print(\"==> Training Node 1\")\n",
    "train_node(node_1, node_1_train_dataloader, node_1_valid_dataloader, cw=node_1_cw)\n",
    "\n",
    "print(\"==> Training Node 2\")\n",
    "train_node(node_2, node_2_train_dataloader, node_2_valid_dataloader, cw=node_2_cw)\n",
    "\n",
    "print(\"==> Training Node 21\")\n",
    "train_node(node_21, node_21_train_dataloader, node_21_valid_dataloader, cw=node_21_cw)\n",
    "\n",
    "print(\"==> Training Node 22\")\n",
    "train_node(node_22, node_22_train_dataloader, node_22_valid_dataloader, cw=node_22_cw)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
